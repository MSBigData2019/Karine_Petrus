{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TPRNNimbdforstudents.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"TPU"},"cells":[{"metadata":{"colab_type":"text","id":"PBFqSEkKqpCN"},"cell_type":"markdown","source":["# TP RNN \n","# Using Many-to-One for movie rating predicton\n","\n","For any remark or suggestion, please feel free to contact me at:\n","geoffroy.peeters@telecom-paristech.fr\n","\n","Last edit: 2019/01/15 geoffroy.peeters@telecom-paristech.fr\n","\n","### Objective:\n","We will implement two different networks to perform automatic rating (0 or 1) of a movie given the text of its review.\n","We will use the ```imdb``` (internet movie database) dataset.\n","\n","The reviews are already available in the form of indexes that point to a word dictionary: each word is already encoded as an index in the dictionary."]},{"metadata":{"colab_type":"text","id":"QmkCSNaXLqjh"},"cell_type":"markdown","source":["### Import packages"]},{"metadata":{"colab_type":"code","id":"AOqjzDwioJj9","colab":{}},"cell_type":"code","source":["import numpy\n","from keras.datasets import imdb\n","from keras.models import Sequential\n","from keras.preprocessing import sequence\n","from keras.layers import Dense, Activation, Embedding, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n","from keras import Model\n","from keras import backend as K\n","#import tensorflow as tf\n","#from tensorflow.keras.models import Sequential\n","#from tensorflow.keras.layers import Input, Dense, LSTM, Flatten, Dropout, Activation\n","#from tensorflow.keras import backend as K\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"v5Yp4OQVvUtr"},"cell_type":"markdown","source":["## Parameters of the model\n","\n","-  We only consider the ```top_words``` first words in the word dictionary\n","- We truncate/zerp-pad each sequence a length ```max_review_length````"]},{"metadata":{"colab_type":"code","id":"4C_Pv7rYvRkM","colab":{}},"cell_type":"code","source":["top_words = 5000 \n","max_review_length = 100\n","INDEX_FROM = 3"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"ZsNcRimyLzgP"},"cell_type":"markdown","source":["## Import IMDB data"]},{"metadata":{"colab_type":"code","id":"5Gfe1ex8oN8Q","colab":{}},"cell_type":"code","source":["# Import the IMDB data and only consider the ``top_words``` most used words\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words, index_from=INDEX_FROM)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"iSc5LmksOLyr"},"cell_type":"markdown","source":["## Data content\n","\n","- ```X_train``` and ```X_test``` are numpy arrays of lists. \n","  - each item in a list is the index in the word dictionary. So that a list is the sequence of index of words.\n","\n","- ```y_train``` and ```y_test``` are a numpy arrays of the same dimension as ```X_train``` and ```X_test``` \n","  - they contains the values 0 (bad movie) or 1 (good movie)"]},{"metadata":{"colab_type":"code","id":"WouODCPrtiuu","outputId":"a4508df2-d415-4c8d-fff8-e093f8c08c9a","executionInfo":{"status":"ok","timestamp":1551866617256,"user_tz":-60,"elapsed":11877,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":489}},"cell_type":"code","source":["print(\"type(X_train):\", type(X_train))\n","print(\"number of training sequences: X_train.shape:\", X_train.shape)\n","print(\"type(X_train[0]):\",type(X_train[0]))\n","print(\"length of the first training sequence: len(X_train[0]):\",len(X_train[0]))\n","print(\"length of the second training sequence: len(X_train[0]):\",len(X_train[1]))\n","print(\"list of data of the first training sequence: X_train[0]:\", X_train[0] )\n","len_list = [len(train) for train in X_train]\n","print(\"maximum length of a training sequence:\", max(len_list))\n","\n","import matplotlib.pyplot as plt\n","plt.hist(len_list, 100);"],"execution_count":25,"outputs":[{"output_type":"stream","text":["type(X_train): <class 'numpy.ndarray'>\n","number of training sequences: X_train.shape: (25000,)\n","type(X_train[0]): <class 'list'>\n","length of the first training sequence: len(X_train[0]): 218\n","length of the second training sequence: len(X_train[0]): 189\n","list of data of the first training sequence: X_train[0]: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n","maximum length of a training sequence: 2494\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"If01nhQP1tNi","colab_type":"text"},"cell_type":"markdown","source":["## Details of how the reviews are encoded"]},{"metadata":{"id":"13xi0MlL1tNo","colab_type":"code","outputId":"53050995-eef6-42bd-e687-30f154ca46db","executionInfo":{"status":"ok","timestamp":1551866619314,"user_tz":-60,"elapsed":13903,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["word_to_id = imdb.get_word_index()\n","word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n","word_to_id[\"<PAD>\"] = 0\n","word_to_id[\"<START>\"] = 1\n","word_to_id[\"<UNK>\"] = 2\n","\n","id_to_word = {value:key for key,value in word_to_id.items()}\n","print(' '.join(id_to_word[id] for id in X_train[1000] ))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["<START> although i had seen <UNK> in a theater way back in <UNK> i couldn't remember anything of the plot except for vague images of kurt thomas running and fighting against a backdrop of stone walls and disappointment regarding the ending br br after reading some of the other reviews i picked up a copy of the newly released dvd to once again enter the world of <UNK> br br it turns out this is one of those films produced during the <UNK> that would go directly to video today the film stars <UNK> <UNK> kurt thomas as jonathan <UNK> <UNK> out of the blue to <UNK> the nation of <UNK> to enter and hopefully win the game a <UNK> <UNK> <UNK> by the khan who <UNK> his people by yelling what sounds like <UNK> power the goal of the mission involves the star wars defense system jonathan is trained in the martial arts by princess <UNK> who never speaks or leaves the house once trained tries to blend in with the <UNK> by wearing a bright red <UNK> with <UNK> of blue and white needless to say <UNK> finds himself running and fighting for his life along the stone streets of <UNK> on his way to a date with destiny and the game br br star kurt thomas was ill served by director robert <UNK> who it looks like was never on the set the so called script is just this side of incompetent see other reviews for the many <UNK> throughout the town of <UNK> has a few good moments but is ultimately ruined by bad editing the ending <UNK> still there's the <UNK> of a good action adventure here a hong kong version with more <UNK> action and faster pace might even be pretty good\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"Hfl42LGCugWB","outputId":"051bba94-517c-48d0-d918-73d7b948ceb9","executionInfo":{"status":"ok","timestamp":1551866619322,"user_tz":-60,"elapsed":13891,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["print(\"type(y_train):\", type(y_train))\n","print(\"y_train.shape:\", y_train.shape)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["type(y_train): <class 'numpy.ndarray'>\n","y_train.shape: (25000,)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"iVw65PNNuobX","outputId":"e976229c-bedc-4617-a077-b4091c377882","executionInfo":{"status":"ok","timestamp":1551866619329,"user_tz":-60,"elapsed":13881,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["print(\"X_test.shape:\", X_test.shape)\n","print(\"y_test.shape:\", y_test.shape)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["X_test.shape: (25000,)\n","y_test.shape: (25000,)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"V18OA7oQNH3c"},"cell_type":"markdown","source":["## Data processing\n","\n","Sequences (represented as a list of values) in ```X_train``` represent the reviews.\n","They can have different length.\n","To train the network we should modify them so that they all have the same length.\n","We do this by:\n","- truncating the ones that are too long\n","- padding-with-zero them the ones that are too short.\n","\n","This is obtained using ```sequence.pad_sequences``` of keras."]},{"metadata":{"id":"I8760lpy2Oby","colab_type":"code","outputId":"fb0a39ac-d788-4f7c-c37b-4f6522d1cbc0","executionInfo":{"status":"ok","timestamp":1551866619334,"user_tz":-60,"elapsed":13868,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"cell_type":"code","source":["# Truncate and pad the review sequences \n","from keras.preprocessing import sequence \n","max_review_length = 100 \n","X_train = sequence.pad_sequences(X_train, maxlen=max_review_length) \n","X_test = sequence.pad_sequences(X_test, maxlen=max_review_length) \n","print(\"len(X_train[0]):\", len(X_train[0]))\n","print(\"len(X_train[1]):\", len(X_train[1]))\n","print(\"X_train[0]:\", X_train[0])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["len(X_train[0]): 100\n","len(X_train[1]): 100\n","X_train[0]: [1415   33    6   22   12  215   28   77   52    5   14  407   16   82\n","    2    8    4  107  117    2   15  256    4    2    7 3766    5  723\n","   36   71   43  530  476   26  400  317   46    7    4    2 1029   13\n","  104   88    4  381   15  297   98   32 2071   56   26  141    6  194\n","    2   18    4  226   22   21  134  476   26  480    5  144   30    2\n","   18   51   36   28  224   92   25  104    4  226   65   16   38 1334\n","   88   12   16  283    5   16 4472  113  103   32   15   16    2   19\n","  178   32]\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"JhmiHsOGoRwT","outputId":"3dd235ce-2eca-4ff1-8bfd-3d1e69b96f93","executionInfo":{"status":"ok","timestamp":1551866619343,"user_tz":-60,"elapsed":13850,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"cell_type":"code","source":["# truncate and pad input sequences\n","\n","# CODE-RNN1-1\n","# --- START CODE HERE\n","# --- END CODE HERE\n","\n","print(\"len(X_train[0]):\", len(X_train[0]))\n","print(\"len(X_train[1]):\", len(X_train[1]))\n","print(\"X_train[0]:\", X_train[0])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["len(X_train[0]): 100\n","len(X_train[1]): 100\n","X_train[0]: [1415   33    6   22   12  215   28   77   52    5   14  407   16   82\n","    2    8    4  107  117    2   15  256    4    2    7 3766    5  723\n","   36   71   43  530  476   26  400  317   46    7    4    2 1029   13\n","  104   88    4  381   15  297   98   32 2071   56   26  141    6  194\n","    2   18    4  226   22   21  134  476   26  480    5  144   30    2\n","   18   51   36   28  224   92   25  104    4  226   65   16   38 1334\n","   88   12   16  283    5   16 4472  113  103   32   15   16    2   19\n","  178   32]\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"YlrDTuk5K65Q"},"cell_type":"markdown","source":["## First model\n","\n","In the first model, we will simply \n","- learn a word embedding  (```Embedding``` layer in keras) and apply it to each of item of a sequence, \n","  -  in keras, embedding is not a matrix going from one-hot-encoding to embedding, it is a layer that goes from index-in-word-dictionary to embedding\n","  - the embedding goes from ```top_words``` dimensions to  ```embedding_vector_length``` dimensions\n","- average the embedding obtained for each word of a seuqnece over all words of the sequence (you should use ```K.mean``` and ```Lambda``` from the keras backend)\n","- apply a fully connected (```Dense``` layer in keras) which output activation is a sigmoid ()predicting the 0 or 1 rating)\n","\n"]},{"metadata":{"colab_type":"code","id":"ufW00TGcs3Jj","colab":{}},"cell_type":"code","source":["K.clear_session()\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X012wooc5Gjt","colab_type":"code","outputId":"e16ecfeb-8d03-48ca-aa36-3cfc499210b4","executionInfo":{"status":"ok","timestamp":1551866619354,"user_tz":-60,"elapsed":13808,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":260}},"cell_type":"code","source":["embedding_vector_length = 32 \n","model = Sequential() \n","#Index-in-word dictionary\n","model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length)) \n","# K.mean and Lambda from the keras backend\n","model.add(Lambda(lambda x: K.mean(x, axis=1, keepdims=False)))\n","#model.add(Lambda(100)) \n","model.add(Dense(1, activation='sigmoid')) \n","#model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n","print(model.summary())"],"execution_count":32,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 100, 32)           160000    \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 32)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 33        \n","=================================================================\n","Total params: 160,033\n","Trainable params: 160,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"pFXz4AS6tawQ","colab":{"base_uri":"https://localhost:8080/","height":228},"outputId":"33c53e3a-f75b-4c32-8861-5558fcff68f7","executionInfo":{"status":"ok","timestamp":1551866626841,"user_tz":-60,"elapsed":21260,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["# compile and fit the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/3\n","25000/25000 [==============================] - 3s 118us/step - loss: 0.6355 - acc: 0.7302 - val_loss: 0.5588 - val_acc: 0.7774\n","Epoch 2/3\n","25000/25000 [==============================] - 2s 94us/step - loss: 0.4841 - acc: 0.8140 - val_loss: 0.4387 - val_acc: 0.8231\n","Epoch 3/3\n","25000/25000 [==============================] - 2s 91us/step - loss: 0.3929 - acc: 0.8456 - val_loss: 0.3854 - val_acc: 0.8360\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f385ee839e8>"]},"metadata":{"tags":[]},"execution_count":33}]},{"metadata":{"colab_type":"text","id":"SBqyzLJRUIsC"},"cell_type":"markdown","source":["## Results\n","\n","After only 3 epochs, you should obtain an accuracy around 84% for the test data."]},{"metadata":{"id":"L8cSHrh81tPT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e6967e51-4db2-467c-c74c-f62d4fbc98ab","executionInfo":{"status":"ok","timestamp":1551866629854,"user_tz":-60,"elapsed":24266,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Accuracy: 83.60%\n"],"name":"stdout"}]},{"metadata":{"id":"X0wSYj4oAMOn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9f50d1d5-2205-4fce-ae17-91d14ebab4b5","executionInfo":{"status":"ok","timestamp":1551866629859,"user_tz":-60,"elapsed":24269,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Accuracy: 83.60%\n"],"name":"stdout"}]},{"metadata":{"id":"rPc5KpIO1tPo","colab_type":"text"},"cell_type":"markdown","source":["## Using the trained embedding to find equivalence between words\n","\n","Since the embedding is part of the models, we can look at the trained embedding matrix $E$ and use it to get the most similar words (according to the trained matrix $E$) in the dictionary.\n","Use the weights of the ```Embedding``` layer to find the most similar words to ```amazing```. We will use an Euclidean distance for that.\n","- Retrieve the weights of the ```Embedding layer```\n","- Get the position of ```amazing``` in the dictionary\n","- Get the word-embedding of ```amazing```\n","- Find (using Euclidean distance), the closest embedded-words to ```amazing```"]},{"metadata":{"id":"Go01eexY1tP3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":243},"outputId":"9a9c7cff-f11e-40cc-ad68-b24b54d561b9","executionInfo":{"status":"ok","timestamp":1551866629863,"user_tz":-60,"elapsed":24270,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["# CODE-RNN1-3\n","# --- START CODE HERE\n","# --- END CODE HERE\n","weights = model.layers[0].get_weights()[0]\n","print(weights)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["[[ 0.01790961  0.02591305 -0.00092555 ...  0.01024847  0.04245038\n","   0.03819277]\n"," [-0.095298   -0.09032033 -0.01398479 ... -0.02592712  0.01254147\n","   0.01933698]\n"," [ 0.03824131  0.04679744  0.04425422 ...  0.03839048 -0.07742004\n","  -0.06311339]\n"," ...\n"," [-0.0495432  -0.04507928 -0.07514504 ... -0.07085038 -0.01545555\n","  -0.02139125]\n"," [-0.02392082 -0.00632902  0.02983558 ...  0.01599907  0.00938911\n","   0.02606635]\n"," [ 0.15491346  0.09940568  0.15296787 ...  0.16258904 -0.17077002\n","  -0.1697252 ]]\n"],"name":"stdout"}]},{"metadata":{"id":"CYWEDGMoCYzh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fc05cba0-bd99-4094-d4b2-3a07bc05070e","executionInfo":{"status":"ok","timestamp":1551866629865,"user_tz":-60,"elapsed":24269,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["weights.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 32)"]},"metadata":{"tags":[]},"execution_count":37}]},{"metadata":{"id":"4X6Xd9X4D9QS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"5e8034c3-8f88-424e-dca7-00cd08e83be4","executionInfo":{"status":"ok","timestamp":1551866629866,"user_tz":-60,"elapsed":24267,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["import numpy as np\n","amazing_id = word_to_id['amazing']\n","weights[word_to_id['amazing']]\n","\n","#np.argsort(weights[word_to_id['amazing']])\n","#np.sort(weights[word_to_id['amazing']])\n"," #id_to_word('22')\n","#id_to_word[(weights[word_to_id['amazing']])]\n","# or access the embedding layer through the constructed model \n","# first `0` refers to the position of embedding layer in the `model`\n","#embeddings = model.layers[0].get_weights()[0]\n","\n","# `embeddings` has a shape of (num_vocab, embedding_dim) \n","\n","# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n","#words_embeddings = {w:embeddings[idx] for w, idx in word_to_index.items()}\n","\n","# now you can use it like this for example\n","#print(words_embeddings['amazing']) \n","def distance(pointA, pointB):\n","   return np.sqrt(np.sum(pointB - pointA) ** 2)\n","from heapq import nsmallest\n","result = nsmallest(5, weights, lambda p : distance(p, weights[amazing_id] ))\n","for elem in result:\n","  idx = np.where(weights == elem)[0][0]\n","  keys = [key for key, value in word_to_id.items() if value == idx]\n","  print(keys)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["['amazing']\n","['8']\n","['highly']\n","['recommended']\n","['7']\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"zK9e5Eo1Ks2a"},"cell_type":"markdown","source":["## Second model\n","\n","In the second model, we will replace\n","- average the obtained embedding over the sequence (use ```K.mean``` and ```Lambda```from keras backend)\n","- by a RNN layer (more precisely an ```LSTM```) in a Many-To-One configuration with $n_a=100$\n"]},{"metadata":{"colab_type":"code","id":"rwoXuOqqVDOy","colab":{}},"cell_type":"code","source":["K.clear_session()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"7dl-CSMKoViX","outputId":"14e9b165-1cf1-457a-c4ee-e15923cf78fc","executionInfo":{"status":"ok","timestamp":1551866629874,"user_tz":-60,"elapsed":24249,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}},"colab":{"base_uri":"https://localhost:8080/","height":260}},"cell_type":"code","source":["# create the model\n","\n","# CODE-RNN1-4\n","# --- START CODE HERE\n","# --- END CODE HERE\n","embedding_vector_length = 32 \n","model = Sequential() \n","#Index-in-word dictionary\n","model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length)) \n","# K.mean and Lambda from the keras backend\n","#model.add(Lambda(lambda x: K.mean(x, axis=1, keepdims=False)))\n","model.add(LSTM(100))\n","#model.add(Lambda(100)) \n","model.add(Dense(1, activation='sigmoid')) \n","#model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n","#print(model.summary())\n","print(model.summary())"],"execution_count":40,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 100, 32)           160000    \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 100)               53200     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 101       \n","=================================================================\n","Total params: 213,301\n","Trainable params: 213,301\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"-bp7PzX7oXtB","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"74d4f547-b3d7-4f39-e51e-97f08e8622d6","executionInfo":{"status":"ok","timestamp":1551866946851,"user_tz":-60,"elapsed":307273,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["# compile and fit the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","\n","model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/3\n","25000/25000 [==============================] - 103s 4ms/step - loss: 0.4520 - acc: 0.7765 - val_loss: 0.3696 - val_acc: 0.8304\n","Epoch 2/3\n","25000/25000 [==============================] - 101s 4ms/step - loss: 0.3053 - acc: 0.8753 - val_loss: 0.3474 - val_acc: 0.8492\n","Epoch 3/3\n","25000/25000 [==============================] - 101s 4ms/step - loss: 0.2724 - acc: 0.8898 - val_loss: 0.3544 - val_acc: 0.8436\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f384f9b8d68>"]},"metadata":{"tags":[]},"execution_count":42}]},{"metadata":{"colab_type":"text","id":"F1LN_fjMWBHJ"},"cell_type":"markdown","source":["## Results\n","\n","After only 3 epochs, you should obtain an accuracy around 88% for the test data."]},{"metadata":{"colab_type":"code","id":"RlMEKRbzoavm","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d06b1616-12fe-452a-f37c-7d6c8a03da7f","executionInfo":{"status":"ok","timestamp":1551866960460,"user_tz":-60,"elapsed":306335,"user":{"displayName":"Karine Petrus","photoUrl":"","userId":"13240032494053762466"}}},"cell_type":"code","source":["# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Accuracy: 84.36%\n"],"name":"stdout"}]},{"metadata":{"id":"0wBd89_pULEN","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}