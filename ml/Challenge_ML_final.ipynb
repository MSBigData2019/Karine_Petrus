{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenge_ML_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NJyLhv6zzs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q dropbox\n",
        "import dropbox\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import pandas as pd\n",
        "\n",
        "import dropbox\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Flatten, Dense, ZeroPadding2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras import regularizers \n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8M5xtl1SZjk",
        "colab_type": "text"
      },
      "source": [
        "This challenge consists in classifying images. However we do not know what are the meaning of 1 and 0 so it is difficult to do relevant features engineering. Moreover, it is problem of image classification, by reading the literature, we can see that the best solution to tackle these kind of problems are the neural network. Besides, there are a lot of pretrained models, on images, which are available, so i have used these models to initialize the weights of the first layers ( 𝑡𝑟𝑎𝑛𝑠𝑓𝑒𝑟 𝑙𝑒𝑎𝑟𝑛𝑖𝑛𝑔 ). Since I have decided to use neural networks, I have not found the use of doing feature engineering since the neural network is doing it (find the good features by himself). The most difficult part is find the best environment, calculus power to train the model and to tune it (I have done it by putting by hand since the library hyperopt was too time consuming)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuIB-ASJSid5",
        "colab_type": "text"
      },
      "source": [
        "#Working environment : Google colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtV3pwqlSpTS",
        "colab_type": "text"
      },
      "source": [
        "In order to make the simulation faster and in order ton have less problem with the potential crash of the environment, I have used the google colab environment in order to use TPU ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu4W0R7Az20O",
        "colab_type": "code",
        "outputId": "e35bbdc5-2d72-4d5e-8293-fd8c6cef7c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1183
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/486li09u91zyjdm/db_train.raw?dl=1\n",
        "!wget https://www.dropbox.com/s/d2hsorvtla3rtf9/label_2019_train.txt?dl=1\n",
        "!wget https://www.dropbox.com/s/mnido8qbwmbi79h/db_test.raw\n",
        "!mv db_train.raw?dl=1 db_train.raw\n",
        "!mv db_val.raw?dl=1 db_val.raw\n",
        "!mv label_2019_train.txt?dl=1 label_2019_train.txt\n",
        "!mv db_test.raw?dl=1 db_test.raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-05 16:15:32--  https://www.dropbox.com/s/486li09u91zyjdm/db_train.raw?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/486li09u91zyjdm/db_train.raw [following]\n",
            "--2019-04-05 16:15:32--  https://www.dropbox.com/s/dl/486li09u91zyjdm/db_train.raw\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7f861e51953cd9e9802c330625.dl.dropboxusercontent.com/cd/0/get/Aee5ihFscvRpLYNdLfPQi3eKSgrkSKv7z0_87HeZNMzjrjiv0aF4hnvgomn9exieeyrjuWxThp2ZdUjV1cUJAbeti8T8XNs-FLIr7bs5B6TPIABIZvtBUOiwg_3quJcR9Gw/file?dl=1# [following]\n",
            "--2019-04-05 16:15:32--  https://uc7f861e51953cd9e9802c330625.dl.dropboxusercontent.com/cd/0/get/Aee5ihFscvRpLYNdLfPQi3eKSgrkSKv7z0_87HeZNMzjrjiv0aF4hnvgomn9exieeyrjuWxThp2ZdUjV1cUJAbeti8T8XNs-FLIr7bs5B6TPIABIZvtBUOiwg_3quJcR9Gw/file?dl=1\n",
            "Resolving uc7f861e51953cd9e9802c330625.dl.dropboxusercontent.com (uc7f861e51953cd9e9802c330625.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc7f861e51953cd9e9802c330625.dl.dropboxusercontent.com (uc7f861e51953cd9e9802c330625.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1092805056 (1.0G) [application/binary]\n",
            "Saving to: ‘db_train.raw?dl=1’\n",
            "\n",
            "db_train.raw?dl=1   100%[===================>]   1.02G  49.7MB/s    in 23s     \n",
            "\n",
            "2019-04-05 16:15:56 (45.9 MB/s) - ‘db_train.raw?dl=1’ saved [1092805056/1092805056]\n",
            "\n",
            "--2019-04-05 16:15:57--  https://www.dropbox.com/s/d2hsorvtla3rtf9/label_2019_train.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/d2hsorvtla3rtf9/label_2019_train.txt [following]\n",
            "--2019-04-05 16:15:57--  https://www.dropbox.com/s/dl/d2hsorvtla3rtf9/label_2019_train.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1248de6756b94b06ca62421ae0.dl.dropboxusercontent.com/cd/0/get/AefX11SxyOClj-m12tgJU23J6r9KxStCMqELMq71-GbE9ZrgpFTzsGFpUsZ1d2mnAE5kiO6nTiF2MhktJoEdYF3O-iYudgw6syaiV5i4ti35C_c6pqAmv704Q2PCiBVFqSM/file?dl=1# [following]\n",
            "--2019-04-05 16:15:57--  https://uc1248de6756b94b06ca62421ae0.dl.dropboxusercontent.com/cd/0/get/AefX11SxyOClj-m12tgJU23J6r9KxStCMqELMq71-GbE9ZrgpFTzsGFpUsZ1d2mnAE5kiO6nTiF2MhktJoEdYF3O-iYudgw6syaiV5i4ti35C_c6pqAmv704Q2PCiBVFqSM/file?dl=1\n",
            "Resolving uc1248de6756b94b06ca62421ae0.dl.dropboxusercontent.com (uc1248de6756b94b06ca62421ae0.dl.dropboxusercontent.com)... 162.125.3.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc1248de6756b94b06ca62421ae0.dl.dropboxusercontent.com (uc1248de6756b94b06ca62421ae0.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 232314 (227K) [application/binary]\n",
            "Saving to: ‘label_2019_train.txt?dl=1’\n",
            "\n",
            "label_2019_train.tx 100%[===================>] 226.87K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-04-05 16:15:58 (2.83 MB/s) - ‘label_2019_train.txt?dl=1’ saved [232314/232314]\n",
            "\n",
            "--2019-04-05 16:15:59--  https://www.dropbox.com/s/mnido8qbwmbi79h/db_test.raw\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/mnido8qbwmbi79h/db_test.raw [following]\n",
            "--2019-04-05 16:15:59--  https://www.dropbox.com/s/raw/mnido8qbwmbi79h/db_test.raw\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com/cd/0/inline/AecT5-uf1O0jRUP7VjlCwjOFQ2X0LCrRGVgB7I31LgLnRl04VQRzOpcktj1EE6D7znrioMs6NqTXTaDrciQF6GSnkOOu5wCIQZdiqJuk0OOXdGwrtUCEhXUvNJyEsXIdEIA/file# [following]\n",
            "--2019-04-05 16:16:00--  https://uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com/cd/0/inline/AecT5-uf1O0jRUP7VjlCwjOFQ2X0LCrRGVgB7I31LgLnRl04VQRzOpcktj1EE6D7znrioMs6NqTXTaDrciQF6GSnkOOu5wCIQZdiqJuk0OOXdGwrtUCEhXUvNJyEsXIdEIA/file\n",
            "Resolving uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com (uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com (uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AeduYPtY4_0ei_Sl2S_YUcQNbxSSP4xibpj44WShvekpL8QiGMUdm0c0tCDZ9rXeis6jtbdcSk-6Kp_FcD8q2iDL27iUcG7A7B6vZozbY6pvFXtCBRbREC15f276_MttK4kR2KEOm97Ankr-HOYbwdk2oTC9OZvrWdHsJJOZl7z4BtMLw3mzrRRZiuWN0zsPDYvFEyk84CJ-efW76NjYkWSUfcvUl8I0mpecYRxV-HoGeQt92qZFSI3Z9N3wJ57DuI1diPp0l8ZYfyKZzfhHy9DlGY-zXWr9xxLK6EqGSNvqLvSZdbWRxxuo-5Bp2IWTGTUO05LVs95zbfaGxho1YH5Ysj5_ZlztbX-2YUvKlx-ZZQ/file [following]\n",
            "--2019-04-05 16:16:00--  https://uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com/cd/0/inline2/AeduYPtY4_0ei_Sl2S_YUcQNbxSSP4xibpj44WShvekpL8QiGMUdm0c0tCDZ9rXeis6jtbdcSk-6Kp_FcD8q2iDL27iUcG7A7B6vZozbY6pvFXtCBRbREC15f276_MttK4kR2KEOm97Ankr-HOYbwdk2oTC9OZvrWdHsJJOZl7z4BtMLw3mzrRRZiuWN0zsPDYvFEyk84CJ-efW76NjYkWSUfcvUl8I0mpecYRxV-HoGeQt92qZFSI3Z9N3wJ57DuI1diPp0l8ZYfyKZzfhHy9DlGY-zXWr9xxLK6EqGSNvqLvSZdbWRxxuo-5Bp2IWTGTUO05LVs95zbfaGxho1YH5Ysj5_ZlztbX-2YUvKlx-ZZQ/file\n",
            "Reusing existing connection to uc5a10504d9d92ef416bac6947fa.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 559108032 (533M) [application/octet-stream]\n",
            "Saving to: ‘db_test.raw.1’\n",
            "\n",
            "db_test.raw.1       100%[===================>] 533.21M  32.3MB/s    in 14s     \n",
            "\n",
            "2019-04-05 16:16:16 (36.8 MB/s) - ‘db_test.raw.1’ saved [559108032/559108032]\n",
            "\n",
            "mv: cannot stat 'db_val.raw?dl=1': No such file or directory\n",
            "mv: cannot stat 'db_test.raw?dl=1': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6OgxWlsSx2h",
        "colab_type": "text"
      },
      "source": [
        "# Metric used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAbTkdQuz2Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_pred(y_true, y_pred):\n",
        "  \n",
        "    class_id_preds = K.cast(K.round(y_pred), 'float32')\n",
        "    N = K.cast(K.shape(y_true)[0], 'float32')\n",
        "    N1 = K.sum(y_true)\n",
        "    N0 = N - N1\n",
        "    \n",
        "    val = ((1. / N0) * K.sum((K.ones_like(y_true) - y_true) * (K.ones_like(y_true) - class_id_preds))) + ((1. / N1) * K.sum(y_true * class_id_preds))\n",
        "\n",
        "    return val / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5u2QbCHS1O_",
        "colab_type": "text"
      },
      "source": [
        "# Exploring the data and reshaping it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sykX9yxez83N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_fname = 'db_train.raw'\n",
        "train_labels_fname = 'label_2019_train.txt'\n",
        "val_images_fname    = 'db_test.raw'\n",
        "\n",
        "# number of images\n",
        "num_train_images = 116157\n",
        "num_valid_images = 59429\n",
        "\n",
        "#The images have the size of 56*56 pixels and are in colors (RGB layers, 3 layers)\n",
        "width = 56\n",
        "height = 56\n",
        "layers = 3\n",
        "dim_image = width*height*layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRFzZ5Hjz9CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(train_images_fname, 'rb') as f:\n",
        "    train_images_data = np.fromfile(f, dtype=np.uint8, count=num_train_images * image_dim)\n",
        "    train_images_data = train_images_data.reshape(num_train_images, width, height, layers)\n",
        "train_images_label = np.loadtxt(train_labels_fname, dtype=np.float64)\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_images_data, train_images_label, test_size = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuoE1LjlTuj2",
        "colab_type": "text"
      },
      "source": [
        "## 2 classes and unbalanced data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZbrq8t8SNni",
        "colab_type": "code",
        "outputId": "dc8b093d-8fc8-4c3c-fe92-014a14b201e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataframe_ytrain = pd.DataFrame(y_train)\n",
        "print('There are ' + str(round(len(dataframe_ytrain[dataframe_ytrain==1].dropna())/len(dataframe_ytrain),2)*100) + '% of class 1')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 59.0% of class 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_pdduTVUlx7",
        "colab_type": "text"
      },
      "source": [
        "Observation: \n",
        "There are 2 classes so in the neural network, we should use as activation function the sigmoid.\n",
        "The data is a little bit unbalanced, we could use a function when putting the weight, such that it takes into account the data is unbalanced (in this case, it didn't change anything). I could also resample the data, and make some data augmentation such that the dataset for the training would be balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QtZd6nw9gvQi"
      },
      "source": [
        "##Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvsp3lvKXMDQ",
        "colab_type": "text"
      },
      "source": [
        "It was very difficult what was the meaning of the labels, and thus to do some relevant features engineering, therefore I have let the neural network find it for me.\n",
        "The only thing I tried was data augmentation, in order to have more training data and make it more precised. However I have had some memory problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIeskBxHYQl6",
        "colab_type": "text"
      },
      "source": [
        "#MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfnunqWCYXxh",
        "colab_type": "text"
      },
      "source": [
        "In this part, I have looked in the litterature what kind of models exist to classify images . It turns out that there exist many models as  𝑉𝐺𝐺16, 𝑉𝐺𝐺19, 𝐼𝑛𝑐𝑒𝑝𝑡𝑖𝑜𝑛, 𝑋𝑐𝑒𝑝𝑡𝑖𝑜𝑛  I have thus, used these models in order to extract the features of the images. Indeed I have initialised the weight of the model by using a pretrained model.\n",
        "\n",
        "I have also used a batch normalisation in order to solve the problem of convariate shift. This normalize the the output.\n",
        "\n",
        "I have tried different pretrained models : VGG16, VGG19, InceptionV3, Xception\n",
        "\n",
        "I have tried to use different number of layers : 4, 5, 9, 2\n",
        "\n",
        "I have tried a dropout with different values : 0.1, 0.5, 0.001, None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpW0UnRfDTOA",
        "colab_type": "code",
        "outputId": "4deadc88-2bfb-4c58-e46f-abf6e0c79ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "#input_img = Input(shape = (pixels, pixels, layers))\n",
        "#pretrained_model = VGG16(input_tensor=input_img, include_top=False, weights='imagenet')\n",
        "#pretrained_model =InceptionV3(input_tensor=input_img, include_top=False, weights='imagenet')\n",
        "input_img = Input(shape = (width, height, layers))\n",
        "pretrained_model = VGG16(input_tensor=input_img, include_top=False, weights='imagenet')\n",
        "#pretrained_model =InceptionV3(input_tensor=input_img, include_top=False, weights='imagenet')\n",
        "\n",
        "# Store the fully connected layers\n",
        "\n",
        "fc1 = pretrained_model.layers[-4]\n",
        "fc2 = pretrained_model.layers[-3]\n",
        "fc3 = pretrained_model.layers[-2]\n",
        "predictions = pretrained_model.layers[-1]\n",
        "\n",
        "# Reconnect the layers\n",
        "output = fc1.output\n",
        "output = fc2(output)\n",
        "output = fc3(output)\n",
        "output = predictions(output)\n",
        "output = Dropout(0.1)(output)\n",
        "output = BatchNormalization()(output)\n",
        "output = Flatten()(output)\n",
        "#Since there is only 2 classes, the activation function which should be used is the sigmoid\n",
        "output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "# Create a new model\n",
        "model = Model(inputs = input_img, outputs = output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsRjU8XGYm8n",
        "colab_type": "text"
      },
      "source": [
        "# Use of TPU for speeding the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R59HnMNy0Nzk",
        "colab_type": "code",
        "outputId": "a70bc9ef-441f-4755-a0d1-d255dbf5c8f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "import os \n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.53.222.74:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 10624882065354502810)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3881875311860525745)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17190790113684726099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5556047150794322527)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17093710424413952139)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9754936608284367581)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 16041957396861684717)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1535347288687685103)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7175517813208858339)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16271476656360374663)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 8689182193821124546)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlmYgqZUYxpX",
        "colab_type": "text"
      },
      "source": [
        "#  Use of different optimizers, learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1AI_-Ue0SS3",
        "colab_type": "code",
        "outputId": "b8d4d509-a45f-4807-d918-349a0f32d42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.compile(optimizer=SGD(lr=0.001, momentum=0.9),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[mean_pred])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Cloning SGD {'lr': 0.0010000000474974513, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wUTHmq2Y077",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to7OkGBvhzkZ",
        "colab_type": "text"
      },
      "source": [
        "I have tried different batch_size = 32, 64 and different number of epochs = 20, 30, 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvO2le9N0UGV",
        "colab_type": "code",
        "outputId": "51f9cda8-4e55-4bd0-d654-b29a06fb0fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1531
        }
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, batch_size=32)\n",
        "model.evaluate(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 114995 samples, validate on 1162 samples\n",
            "Epoch 1/20\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 56, 56, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 1), dtype=tf.float32, name='dense_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.0010000000474974513, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f75f50a5ba8> []\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 9.220485210418701 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU momentum: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            "114880/114995 [============================>.] - ETA: 0s - loss: 0.6641 - mean_pred: 0.5566INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(2, 56, 56, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 1), dtype=tf.float32, name='dense_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f75f50a5ba8> [<tf.Variable 'tpu_140144604159560/SGD/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f34c3748>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f34c3a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f34c3f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f349b940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f340ddd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f33cff60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f3377ba8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f333a6d8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f32c8518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f326f6a0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f3237780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f31fe198>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f31c3e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f3155b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f30fa0b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f30bfe80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f3086a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2ff0f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f304b630>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2f81b00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2f486a0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2f0dc88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2e7f1d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2e43710>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2e09940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2d76908>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2d3c518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2d5d518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2d03fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f75f2c70940>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 7.960665464401245 secs\n",
            "114976/114995 [============================>.] - ETA: 0s - loss: 0.6641 - mean_pred: 0.5567INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(4, 56, 56, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 1), dtype=tf.float32, name='dense_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.0010000000474974513, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f75f08e4dd8> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 3.5473575592041016 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(1,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(1, 56, 56, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(1, 1), dtype=tf.float32, name='dense_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f75f08e4dd8> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.613373279571533 secs\n",
            "114995/114995 [==============================] - 124s 1ms/sample - loss: 0.6640 - mean_pred: 0.5566 - val_loss: 0.5779 - val_mean_pred: 0.6728\n",
            "Epoch 2/20\n",
            "114995/114995 [==============================] - 75s 654us/sample - loss: 0.5578 - mean_pred: 0.6885 - val_loss: 0.4462 - val_mean_pred: 0.7782\n",
            "Epoch 3/20\n",
            "114995/114995 [==============================] - 75s 648us/sample - loss: 0.4823 - mean_pred: 0.7579 - val_loss: 0.4004 - val_mean_pred: 0.7921\n",
            "Epoch 4/20\n",
            "114995/114995 [==============================] - 75s 651us/sample - loss: 0.4498 - mean_pred: 0.7853 - val_loss: 0.3817 - val_mean_pred: 0.8217\n",
            "Epoch 5/20\n",
            "114995/114995 [==============================] - 75s 654us/sample - loss: 0.4377 - mean_pred: 0.7959 - val_loss: 0.4005 - val_mean_pred: 0.8234\n",
            "Epoch 6/20\n",
            "114995/114995 [==============================] - 74s 646us/sample - loss: 0.4222 - mean_pred: 0.8068 - val_loss: 0.3507 - val_mean_pred: 0.8303\n",
            "Epoch 7/20\n",
            "114995/114995 [==============================] - 75s 651us/sample - loss: 0.4096 - mean_pred: 0.8146 - val_loss: 0.3754 - val_mean_pred: 0.8258\n",
            "Epoch 8/20\n",
            "114995/114995 [==============================] - 74s 645us/sample - loss: 0.3983 - mean_pred: 0.8226 - val_loss: 0.3711 - val_mean_pred: 0.8321\n",
            "Epoch 9/20\n",
            "114995/114995 [==============================] - 74s 643us/sample - loss: 0.3894 - mean_pred: 0.8270 - val_loss: 0.3461 - val_mean_pred: 0.8421\n",
            "Epoch 10/20\n",
            "114995/114995 [==============================] - 74s 644us/sample - loss: 0.3797 - mean_pred: 0.8325 - val_loss: 0.3495 - val_mean_pred: 0.8381\n",
            "Epoch 11/20\n",
            "114995/114995 [==============================] - 75s 650us/sample - loss: 0.3716 - mean_pred: 0.8385 - val_loss: 0.3634 - val_mean_pred: 0.8420\n",
            "Epoch 12/20\n",
            "114995/114995 [==============================] - 75s 650us/sample - loss: 0.3627 - mean_pred: 0.8443 - val_loss: 0.3942 - val_mean_pred: 0.8392\n",
            "Epoch 13/20\n",
            "114995/114995 [==============================] - 74s 643us/sample - loss: 0.3535 - mean_pred: 0.8508 - val_loss: 0.4080 - val_mean_pred: 0.8486\n",
            "Epoch 14/20\n",
            "114995/114995 [==============================] - 75s 651us/sample - loss: 0.3410 - mean_pred: 0.8585 - val_loss: 0.4296 - val_mean_pred: 0.8359\n",
            "Epoch 15/20\n",
            "114995/114995 [==============================] - 75s 652us/sample - loss: 0.3312 - mean_pred: 0.8643 - val_loss: 0.4035 - val_mean_pred: 0.8531\n",
            "Epoch 16/20\n",
            "114995/114995 [==============================] - 74s 646us/sample - loss: 0.3196 - mean_pred: 0.8697 - val_loss: 0.4210 - val_mean_pred: 0.8314\n",
            "Epoch 17/20\n",
            "114995/114995 [==============================] - 74s 646us/sample - loss: 0.3060 - mean_pred: 0.8786 - val_loss: 0.4108 - val_mean_pred: 0.8381\n",
            "Epoch 18/20\n",
            "114995/114995 [==============================] - 74s 646us/sample - loss: 0.2959 - mean_pred: 0.8839 - val_loss: 0.4871 - val_mean_pred: 0.8227\n",
            "Epoch 19/20\n",
            "114995/114995 [==============================] - 76s 662us/sample - loss: 0.2882 - mean_pred: 0.8870 - val_loss: 0.5040 - val_mean_pred: 0.8368\n",
            "Epoch 20/20\n",
            "114995/114995 [==============================] - 77s 668us/sample - loss: 0.2785 - mean_pred: 0.8922 - val_loss: 0.4456 - val_mean_pred: 0.8466\n",
            "114976/114995 [============================>.] - ETA: 0s - loss: 0.1478 - mean_pred: 0.9447INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 56, 56, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 1), dtype=tf.float32, name='dense_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f75f08e4dd8> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.7739157676696777 secs\n",
            "114995/114995 [==============================] - 52s 448us/sample - loss: 0.1478 - mean_pred: 0.9447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1478011758817352, 0.9447194]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSKqOrd3Y6VP",
        "colab_type": "text"
      },
      "source": [
        "#  Predicting the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xMhhHsTht1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(val_images_fname, 'rb') as f:\n",
        "    val_images_data = np.fromfile(f, dtype=np.uint8, count=num_valid_images * image_dim).astype(np.float32)\n",
        "    val_images_data = val_images_data.reshape(num_valid_images, width, height, layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KWauiyg0eWE",
        "colab_type": "code",
        "outputId": "74c0cdac-a777-4632-8775-94d888a7ce6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "cpu_model = model.sync_to_cpu()\n",
        "val_pred = cpu_model.predict(val_images_data)\n",
        "val_pred = np.where(val_pred >= 0.5, 1, 0)\n",
        "np.savetxt(\"val_pred3.txt\", val_pred, fmt=\"%d\")\n",
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU momentum: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU nesterov: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryvhhIcKFXKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waQI8cTZ5lab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('val_pred3.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}